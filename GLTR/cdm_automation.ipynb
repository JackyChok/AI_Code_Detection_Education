{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Default Frame for CDM test running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jacky\\Desktop\\FIT4701\\FYP\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from gltr_ppl.cdm import GLTRPPLCodeDetector\n",
    "from metrics import MetricsEvaluator\n",
    "import csv\n",
    "import time\n",
    "# import requests\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CsvProcessor:\n",
    "    def __init__(self, input_file, limit=100000):\n",
    "        self.input_file = input_file\n",
    "        self.limit = limit\n",
    "        # Instantiate the other class here\n",
    "\n",
    "    # run_human_test is default to False, if True it will ask api_client to predict the code\n",
    "    def process_csv(\n",
    "        self,\n",
    "        api_client,\n",
    "        human_result_file: str,\n",
    "        output_file: str,\n",
    "        gpt_headers: list,\n",
    "        checkpoint: int,\n",
    "        run_human_test: bool = False,\n",
    "        human_headers: list = [],\n",
    "    ):\n",
    "        self.limit = checkpoint + self.limit\n",
    "        with open(self.input_file, \"r\", encoding=\"utf-8\") as csv_input_file:\n",
    "            with open(human_result_file, \"r\", encoding=\"utf-8\") as csv_human_file:\n",
    "                with open(\n",
    "                    output_file, \"w\", newline=\"\", encoding=\"utf-8\"\n",
    "                ) as csv_output_file:\n",
    "                    input_file_reader = csv.DictReader(csv_input_file)\n",
    "                    csvheaders = (\n",
    "                        input_file_reader.fieldnames + human_headers + gpt_headers\n",
    "                    )\n",
    "                    writer = csv.DictWriter(csv_output_file, fieldnames=csvheaders)\n",
    "                    writer.writeheader()\n",
    "                    index = 0\n",
    "                    print(\"WORKING ON SOLUTION\")\n",
    "                    if not run_human_test:\n",
    "                        human_res_reader = csv.DictReader(csv_human_file)\n",
    "                        for input_row, human_res_row in zip(\n",
    "                            input_file_reader, human_res_reader\n",
    "                        ):\n",
    "                            gpt_result = [\"\"] * len(gpt_headers)\n",
    "                            if checkpoint <= index < self.limit:\n",
    "                                print(f\"checkpoint: {index} ----- {input_row['index']}\")\n",
    "                                retries = 0\n",
    "                                while retries < 2:\n",
    "                                    try:\n",
    "                                        gpt_result = api_client.text_predict_tuple(\n",
    "                                            str(input_row[\"GPT Answer\"].encode(\"utf-8\"))\n",
    "                                        )\n",
    "                                        # print(gpt_result)\n",
    "                                        break\n",
    "                                    except Exception as e:\n",
    "                                        retries += 1\n",
    "                                        print(f\"Error calling API: {e}. Retrying...\")\n",
    "                                        if retries >= 2:\n",
    "                                            print(\n",
    "                                                \"Max retries reached for row \",\n",
    "                                                input_row[\"index\"],\n",
    "                                                \". Skipping...\",\n",
    "                                            )\n",
    "                                        time.sleep(0.25)\n",
    "                                new_row = {\n",
    "                                \"index\": input_row[\n",
    "                                    \"index\"\n",
    "                                ],  # \\ufeffindex for goodanswer\n",
    "                                \"Source Name\": input_row[\"Source Name\"],\n",
    "                                \"local index\": input_row[\"local index\"],\n",
    "                                \"Problem\": input_row[\"Problem\"],\n",
    "                                \"Python Code\": input_row[\"Python Code\"],\n",
    "                                \"GPT Answer\": input_row[\"GPT Answer\"],\n",
    "                                \"variant\": input_row[\"variant\"],\n",
    "                                }\n",
    "                                for idx, header in enumerate(human_headers):\n",
    "                                    new_row[header] = human_res_row[header]\n",
    "                                for idx, header in enumerate(gpt_headers):\n",
    "                                    new_row[header] = gpt_result[idx]\n",
    "                                writer.writerow(new_row)\n",
    "                            elif index >= self.limit:\n",
    "                                break\n",
    "                            index += 1\n",
    "                    else:\n",
    "                        for row in input_file_reader:\n",
    "                            human_result = [\"\"] * len(human_headers)\n",
    "                            gpt_result = [\"\"] * len(gpt_headers)\n",
    "                            if checkpoint <= index < self.limit:\n",
    "                                print(f\"checkpoint: {index} ----- {row['index']}\")\n",
    "                                retries = 0\n",
    "                                while retries < 2:\n",
    "                                    try:\n",
    "                                        # print(row['Python Code'], row[\"GPT Answer\"])\n",
    "                                        # print(row['index'])\n",
    "                                        human_result = api_client.text_predict_tuple(\n",
    "                                            str(row[\"Python Code\"].encode(\"utf-8\"))\n",
    "                                        )\n",
    "                                        # time.sleep(0.5)\n",
    "                                        gpt_result = api_client.text_predict_tuple(\n",
    "                                            str(row[\"GPT Answer\"].encode(\"utf-8\"))\n",
    "                                        )\n",
    "                                        # print(gpt_result)\n",
    "                                        break\n",
    "                                    except Exception as e:\n",
    "                                        retries += 1\n",
    "                                        print(f\"Error calling API: {e}. Retrying...\")\n",
    "                                        if retries >= 2:\n",
    "                                            print(\n",
    "                                                \"Max retries reached for row \",\n",
    "                                                row[\"index\"],\n",
    "                                                \". Skipping...\",\n",
    "                                            )\n",
    "                                        time.sleep(0.25)\n",
    "                                new_row = {\n",
    "                                    \"index\": row[\"index\"],  # \\ufeffindex for goodanswer\n",
    "                                    \"Source Name\": row[\"Source Name\"],\n",
    "                                    \"local index\": row[\"local index\"],\n",
    "                                    \"Problem\": row[\"Problem\"],\n",
    "                                    \"Python Code\": row[\"Python Code\"],\n",
    "                                    \"GPT Answer\": row[\"GPT Answer\"],\n",
    "                                    \"variant\": row[\"variant\"],\n",
    "                                }\n",
    "                                for idx, header in enumerate(human_headers):\n",
    "                                    new_row[header] = human_result[idx]\n",
    "                                for idx, header in enumerate(gpt_headers):\n",
    "                                    new_row[header] = gpt_result[idx]\n",
    "                                writer.writerow(new_row)\n",
    "                            elif index >= self.limit:\n",
    "                                break\n",
    "                            index += 1\n",
    "                    print(\"------DONE------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global config for all CDMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "variant = 10\n",
    "input_file = f\"variant_{variant}_full.csv\"\n",
    "last_checkpoint = 0\n",
    "csv_processor = CsvProcessor(input_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CDM execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup input file, output file, code detector, CDM name, new col to be added, last checkpoint \n",
    "cdm_name = \"gltr_ppl\"\n",
    "human_result_file = \"gltr_ppl_human.csv\"\n",
    "output_file = f\"{cdm_name}_variants_prompt_{variant}.csv\"\n",
    "new_human_header = [\n",
    "   \"GLTR_answer_human_binary\",\n",
    "   \"PPL_answer_human_binary\",\n",
    "]\n",
    "new_gpt_header = [\n",
    "   \"GLTR_answer_GPT_binary\",\n",
    "   \"PPL_answer_GPT_binary\",\n",
    "]\n",
    "last_checkpoint = 0\n",
    "api_client = GLTRPPLCodeDetector()\n",
    "run_human_test = False\n",
    "csv_processor.process_csv(api_client, human_result_file, output_file, new_gpt_header, last_checkpoint, run_human_test, new_human_header)\n",
    "# # Evaluate Metrics\n",
    "# evaluator = MetricsEvaluator(output_file)\n",
    "# evaluator.calculate(cdm_name,f\"{cdm_name}_results.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
