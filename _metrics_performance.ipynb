{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance Metrics Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine_csvs() help to combine results from all variant together as one file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_csvs(file_paths, output_path):\n",
    "    \"\"\"\n",
    "    Combine multiple CSV files with the same header into a single file.\n",
    "    \n",
    "    :param file_paths: List of paths to the CSV files to combine.\n",
    "    :param output_path: Path to the output combined CSV file.\n",
    "    \"\"\"\n",
    "    with open(output_path, 'w', newline='', encoding=\"utf-8\") as outfile:\n",
    "        writer = None\n",
    "\n",
    "        for i, file_path in enumerate(file_paths):\n",
    "            with open(file_path, 'r', encoding=\"utf-8\") as infile:\n",
    "                reader = csv.reader(infile)\n",
    "                print(i)\n",
    "                # For the first file, write headers and data\n",
    "                if i == 0:\n",
    "                    writer = csv.writer(outfile)\n",
    "                    for row in reader:\n",
    "                        writer.writerow(row)\n",
    "                # For subsequent files, skip the header and write data\n",
    "                else:\n",
    "                    next(reader)  # Skip header\n",
    "                    for row in reader:\n",
    "                        writer.writerow(row)\n",
    "\n",
    "# Example\n",
    "file_paths = []  # Add paths to your CSV files\n",
    "for i in range(1, 15):\n",
    "    input_file = f\"../gpt2outputdetector/results/gpt2outputdetector_variants_prompt_{i}.csv\"\n",
    "    file_paths.append(input_file)\n",
    "output_path = \"combined.csv\"\n",
    "combine_csvs(file_paths, output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After combining all results of same CDM, rename column so that the code can work properly\n",
    "- Human classification result column to 'humanbinary'\n",
    "- GPT classification result column to 'GPTbinary'\n",
    "\n",
    "1 indicates it is Human Written\n",
    "\n",
    "0 indicates it is AI Generated "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "class MetricsEvaluator:\n",
    "    def __init__(self, filename, show_plot = False):\n",
    "        self.show_plot = show_plot\n",
    "        self.data = pd.read_csv(filename)\n",
    "        # print(self.data)\n",
    "    \n",
    "    def calculate_variant(self, column_name, output_file):\n",
    "        # Open the CSV file in write mode\n",
    "        with open(output_file, 'w', encoding='utf-8', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            # Write the header row\n",
    "            writer.writerow([\"Variant\",\"True Positive Rate (TPR)\",\"False Negative Rate (FNR)\",\"True Negative Rate (TNR)\",\"False Positive Rate (FPR)\",\"Accuracy\",\"Precision\",\"Recall\",\"F1 Score\",\"Area Under Curve(AUC)\"])\n",
    "            print(\"            Actual   \")\n",
    "            print(\"       |   | 1  | 0  |\")\n",
    "            print(\"Predict| 1 | tp | fp |\")\n",
    "            print(\"       | 0 | fn | tn |\")\n",
    "            # print(self.data.size)\n",
    "            group_data = self.data.groupby(\"variant\")\n",
    "            # print(group_data.size)\n",
    "            variant_data = []\n",
    "            for key, variant_group in group_data:\n",
    "                # print(variant_group)\n",
    "                variant_data.append(self.get_variant_performance(column_name, variant_group, key, writer))\n",
    "            for variant in variant_data:\n",
    "                writer.writerow([variant[\"variant\"],variant[\"TPR\"],variant[\"FNR\"],variant[\"TNR\"],variant[\"FPR\"],variant[\"accuracy\"],variant[\"precision\"],variant[\"recall\"],variant[\"f1\"],variant[\"auc\"]])\n",
    "            \n",
    "\n",
    "    def get_variant_performance(self, column_name, dataframe, label, writer):\n",
    "        pred_human_col_name = \"humanbinary\"\n",
    "        pred_GPT_col_name = \"GPTbinary\"\n",
    "\n",
    "        pred_human = dataframe[pred_human_col_name]\n",
    "        pred_GPT = dataframe[pred_GPT_col_name]\n",
    "\n",
    "\n",
    "        actual_human = np.ones_like(pred_human)\n",
    "        actual_GPT = np.zeros_like(pred_GPT)\n",
    "\n",
    "        \n",
    "\n",
    "        actual = np.concatenate((actual_human, actual_GPT))\n",
    "        predict = np.concatenate((pred_human, pred_GPT))\n",
    "        combined_auc = roc_auc_score(actual, predict)\n",
    "        cfm = confusion_matrix(actual, predict)\n",
    "        tn, fp, fn, tp = cfm.ravel()\n",
    "        print(\"\\n\\nSIZE: \",actual_human.size, actual_GPT.size)\n",
    "        print(f\"=============== {label} Performance ===============\")\n",
    "        \n",
    "        print(\"For human:\")\n",
    "        print(\"True Positive Rate  (TPR): \", tp/(tp+fn))\n",
    "        print(\"False Negative Rate (FNR): \", fn/(tp+fn))\n",
    "        print(\"For GPT:\")\n",
    "        print(\"True Negative Rate  (TNR): \", tn/(fp+tn))\n",
    "        print(\"False Positive Rate (FPR): \", fp/(fp+tn))\n",
    "\n",
    "        combined = {\n",
    "            \"accuracy\": accuracy_score(actual, predict),\n",
    "            \"precision\": precision_score(actual, predict),\n",
    "            \"recall\": recall_score(actual, predict, zero_division=1),\n",
    "            \"f1\": f1_score(actual, predict),\n",
    "            \"auc\": combined_auc\n",
    "        }\n",
    "        print()\n",
    "        for key, value in combined.items():\n",
    "            print(\"{:<15}: {}\".format(str(key).capitalize(), value))\n",
    "        return {\n",
    "            \"variant\": label,\n",
    "            \"TPR\": tp/(tp+fn),\n",
    "            \"FNR\": fn/(tp+fn),\n",
    "            \"TNR\": tn/(fp+tn),\n",
    "            \"FPR\": fp/(fp+tn),\n",
    "            \"accuracy\": accuracy_score(actual, predict),\n",
    "            \"precision\": precision_score(actual, predict),\n",
    "            \"recall\": recall_score(actual, predict, zero_division=1),\n",
    "            \"f1\": f1_score(actual, predict),\n",
    "            \"auc\": combined_auc\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is an example on how to run the metrics performance evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Actual   \n",
      "       |   | 1  | 0  |\n",
      "Predict| 1 | tp | fp |\n",
      "       | 0 | fn | tn |\n",
      "\n",
      "\n",
      "SIZE:  5069 5069\n",
      "=============== 1 Performance ===============\n",
      "For human:\n",
      "True Positive Rate  (TPR):  0.9128033142631683\n",
      "False Negative Rate (FNR):  0.08719668573683172\n",
      "For GPT:\n",
      "True Negative Rate  (TNR):  0.09587689879660682\n",
      "False Positive Rate (FPR):  0.9041231012033931\n",
      "\n",
      "Accuracy       : 0.5043401065298876\n",
      "Precision      : 0.5023887079261672\n",
      "Recall         : 0.9128033142631683\n",
      "F1             : 0.648084599761888\n",
      "Auc            : 0.5043401065298876\n",
      "\n",
      "\n",
      "SIZE:  5065 5065\n",
      "=============== 2 Performance ===============\n",
      "For human:\n",
      "True Positive Rate  (TPR):  0.9127344521224087\n",
      "False Negative Rate (FNR):  0.08726554787759132\n",
      "For GPT:\n",
      "True Negative Rate  (TNR):  0.08825271470878579\n",
      "False Positive Rate (FPR):  0.9117472852912142\n",
      "\n",
      "Accuracy       : 0.5004935834155972\n",
      "Precision      : 0.5002705334920463\n",
      "Recall         : 0.9127344521224087\n",
      "F1             : 0.6463022508038586\n",
      "Auc            : 0.5004935834155972\n",
      "\n",
      "\n",
      "SIZE:  5064 5064\n",
      "=============== 3 Performance ===============\n",
      "For human:\n",
      "True Positive Rate  (TPR):  0.9127172195892576\n",
      "False Negative Rate (FNR):  0.0872827804107425\n",
      "For GPT:\n",
      "True Negative Rate  (TNR):  0.07958135860979462\n",
      "False Positive Rate (FPR):  0.9204186413902053\n",
      "\n",
      "Accuracy       : 0.49614928909952605\n",
      "Precision      : 0.49789938597436173\n",
      "Recall         : 0.9127172195892576\n",
      "F1             : 0.6443158848539764\n",
      "Auc            : 0.4961492890995261\n",
      "\n",
      "\n",
      "SIZE:  5069 5069\n",
      "=============== 4 Performance ===============\n",
      "For human:\n",
      "True Positive Rate  (TPR):  0.9128033142631683\n",
      "False Negative Rate (FNR):  0.08719668573683172\n",
      "For GPT:\n",
      "True Negative Rate  (TNR):  0.08976129414085618\n",
      "False Positive Rate (FPR):  0.9102387058591438\n",
      "\n",
      "Accuracy       : 0.5012823042020123\n",
      "Precision      : 0.5007033870793204\n",
      "Recall         : 0.9128033142631683\n",
      "F1             : 0.646680642907058\n",
      "Auc            : 0.5012823042020123\n",
      "\n",
      "\n",
      "SIZE:  5069 5069\n",
      "=============== 5 Performance ===============\n",
      "For human:\n",
      "True Positive Rate  (TPR):  0.9128033142631683\n",
      "False Negative Rate (FNR):  0.08719668573683172\n",
      "For GPT:\n",
      "True Negative Rate  (TNR):  0.030380745709212863\n",
      "False Positive Rate (FPR):  0.9696192542907871\n",
      "\n",
      "Accuracy       : 0.4715920299861906\n",
      "Precision      : 0.4849088241458814\n",
      "Recall         : 0.9128033142631683\n",
      "F1             : 0.633358428581206\n",
      "Auc            : 0.4715920299861906\n",
      "\n",
      "\n",
      "SIZE:  5069 5069\n",
      "=============== 6 Performance ===============\n",
      "For human:\n",
      "True Positive Rate  (TPR):  0.9128033142631683\n",
      "False Negative Rate (FNR):  0.08719668573683172\n",
      "For GPT:\n",
      "True Negative Rate  (TNR):  0.04478200828565792\n",
      "False Positive Rate (FPR):  0.9552179917143421\n",
      "\n",
      "Accuracy       : 0.4787926612744131\n",
      "Precision      : 0.48864716443130213\n",
      "Recall         : 0.9128033142631683\n",
      "F1             : 0.6365387260971248\n",
      "Auc            : 0.4787926612744131\n",
      "\n",
      "\n",
      "SIZE:  5069 5069\n",
      "=============== 7 Performance ===============\n",
      "For human:\n",
      "True Positive Rate  (TPR):  0.9128033142631683\n",
      "False Negative Rate (FNR):  0.08719668573683172\n",
      "For GPT:\n",
      "True Negative Rate  (TNR):  0.052870388636811996\n",
      "False Positive Rate (FPR):  0.947129611363188\n",
      "\n",
      "Accuracy       : 0.4828368514499901\n",
      "Precision      : 0.4907721680101824\n",
      "Recall         : 0.9128033142631683\n",
      "F1             : 0.6383389666827619\n",
      "Auc            : 0.48283685144999017\n",
      "\n",
      "\n",
      "SIZE:  5069 5069\n",
      "=============== 8 Performance ===============\n",
      "For human:\n",
      "True Positive Rate  (TPR):  0.9128033142631683\n",
      "False Negative Rate (FNR):  0.08719668573683172\n",
      "For GPT:\n",
      "True Negative Rate  (TNR):  0.1140264351943184\n",
      "False Positive Rate (FPR):  0.8859735648056816\n",
      "\n",
      "Accuracy       : 0.5134148747287434\n",
      "Precision      : 0.5074577758280324\n",
      "Recall         : 0.9128033142631683\n",
      "F1             : 0.6522873052794812\n",
      "Auc            : 0.5134148747287434\n",
      "\n",
      "\n",
      "SIZE:  5069 5069\n",
      "=============== 9 Performance ===============\n",
      "For human:\n",
      "True Positive Rate  (TPR):  0.9128033142631683\n",
      "False Negative Rate (FNR):  0.08719668573683172\n",
      "For GPT:\n",
      "True Negative Rate  (TNR):  0.1071217202604064\n",
      "False Positive Rate (FPR):  0.8928782797395937\n",
      "\n",
      "Accuracy       : 0.5099625172617873\n",
      "Precision      : 0.5055173167267563\n",
      "Recall         : 0.9128033142631683\n",
      "F1             : 0.6506820419069048\n",
      "Auc            : 0.5099625172617873\n",
      "\n",
      "\n",
      "SIZE:  5069 5069\n",
      "=============== 10 Performance ===============\n",
      "For human:\n",
      "True Positive Rate  (TPR):  0.9128033142631683\n",
      "False Negative Rate (FNR):  0.08719668573683172\n",
      "For GPT:\n",
      "True Negative Rate  (TNR):  0.13750246596961926\n",
      "False Positive Rate (FPR):  0.8624975340303808\n",
      "\n",
      "Accuracy       : 0.5251528901163938\n",
      "Precision      : 0.5141682409156573\n",
      "Recall         : 0.9128033142631683\n",
      "F1             : 0.6578049473983508\n",
      "Auc            : 0.5251528901163938\n",
      "\n",
      "\n",
      "SIZE:  5069 5069\n",
      "=============== 11 Performance ===============\n",
      "For human:\n",
      "True Positive Rate  (TPR):  0.9128033142631683\n",
      "False Negative Rate (FNR):  0.08719668573683172\n",
      "For GPT:\n",
      "True Negative Rate  (TNR):  0.06944170447820083\n",
      "False Positive Rate (FPR):  0.9305582955217991\n",
      "\n",
      "Accuracy       : 0.4911225093706846\n",
      "Precision      : 0.4951840753424658\n",
      "Recall         : 0.9128033142631683\n",
      "F1             : 0.6420592520641089\n",
      "Auc            : 0.4911225093706846\n",
      "\n",
      "\n",
      "SIZE:  5069 5069\n",
      "=============== 12 Performance ===============\n",
      "For human:\n",
      "True Positive Rate  (TPR):  0.9128033142631683\n",
      "False Negative Rate (FNR):  0.08719668573683172\n",
      "For GPT:\n",
      "True Negative Rate  (TNR):  0.07871375024659696\n",
      "False Positive Rate (FPR):  0.921286249753403\n",
      "\n",
      "Accuracy       : 0.49575853225488264\n",
      "Precision      : 0.4976874260514144\n",
      "Recall         : 0.9128033142631683\n",
      "F1             : 0.6441598218014757\n",
      "Auc            : 0.49575853225488264\n",
      "\n",
      "\n",
      "SIZE:  5068 5068\n",
      "=============== 13 Performance ===============\n",
      "For human:\n",
      "True Positive Rate  (TPR):  0.9127861089187056\n",
      "False Negative Rate (FNR):  0.08721389108129439\n",
      "For GPT:\n",
      "True Negative Rate  (TNR):  0.07162588792423047\n",
      "False Positive Rate (FPR):  0.9283741120757696\n",
      "\n",
      "Accuracy       : 0.49220599842146806\n",
      "Precision      : 0.4957667988425678\n",
      "Recall         : 0.9127861089187056\n",
      "F1             : 0.6425446211542468\n",
      "Auc            : 0.492205998421468\n"
     ]
    }
   ],
   "source": [
    "# EXAMPLE CODE\n",
    "# Evaluate Metrics\n",
    "cdm_name = \"gpt2outputdetector\"\n",
    "\n",
    "input_file = f\"./Gpt2outputdetector/results/gpt2outputdetector_combined_result_only.csv\"\n",
    "evaluator = MetricsEvaluator(input_file)\n",
    "evaluator.calculate_variant(cdm_name,f\"{cdm_name}_results.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical Test\n",
    "For the accuracy base, copy the base variant (variant 1) 12 time to be compare with the base variant\n",
    "\n",
    "For the accuracy, put the accuracy for each variant of each CDM based on given example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TNR Results for GLTR:\n",
      "Summary: t-stat = 21.0000, p-value = 0.1763\n",
      "\n",
      "\n",
      "TNR Results for GPT-2 Detector:\n",
      "Summary: t-stat = 18.0000, p-value = 0.1099\n",
      "\n",
      "\n",
      "TNR Results for GPTZero:\n",
      "Summary: t-stat = 19.0000, p-value = 0.1294\n",
      "\n",
      "\n",
      "TNR Results for Sapling:\n",
      "Summary: t-stat = 30.0000, p-value = 0.5186\n",
      "\n",
      "\n",
      "TNR Results for DetectGPT:\n",
      "Summary: t-stat = 34.0000, p-value = 0.7334\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import ttest_rel\n",
    "\n",
    "# Sample data\n",
    "# Each row in the data represents a variant and each column represents a detector\n",
    "# Here's some random data for illustration purposes\n",
    "data_accuracy_base = np.array([\n",
    "    [0.5040, 0.5040, 0.5040, 0.5040, 0.5040, 0.5040, 0.5040, 0.5040, 0.5040, 0.5040, 0.5040, 0.5040],  # GLTR\n",
    "    [0.5043, 0.5043, 0.5043, 0.5043, 0.5043, 0.5043, 0.5043, 0.5043, 0.5043, 0.5043, 0.5043, 0.5043],  # GPT-2 Detector\n",
    "    [0.4971, 0.4971, 0.4971, 0.4971, 0.4971, 0.4971, 0.4971, 0.4971, 0.4971, 0.4971, 0.4971, 0.4971],  # GPTZero\n",
    "    [0.6056, 0.6056, 0.6056, 0.6056, 0.6056, 0.6056, 0.6056, 0.6056, 0.6056, 0.6056, 0.6056, 0.6056],  # Sapling\n",
    "    [0.4893, 0.4893, 0.4893, 0.4893, 0.4893, 0.4893, 0.4893, 0.4893, 0.4893, 0.4893, 0.4893, 0.4893]   # DetectGPT\n",
    "])\n",
    "data_accuracy = np.array([\n",
    "    #   2       3       4       5       6       7       8       9      10      11      12      13\n",
    "    [0.4936, 0.4841, 0.6569, 0.6999, 0.6920, 0.7693, 0.4908, 0.4952, 0.4881, 0.5375, 0.5020, 0.6478],  # GLTR\n",
    "    [0.5005, 0.4961, 0.5013, 0.4716, 0.4788, 0.4828, 0.5134, 0.5100, 0.5252, 0.4911, 0.4958, 0.4922],  # GPT-2 Detector\n",
    "    [0.4988, 0.4986, 0.4966, 0.4969, 0.4976, 0.4989, 0.5108, 0.4972, 0.4973, 0.4970, 0.4965, 0.5824],  # GPTZero\n",
    "    [0.5961, 0.6031, 0.6048, 0.5425, 0.5827, 0.6083, 0.6630, 0.6258, 0.6811, 0.6187, 0.6059, 0.6528],  # Sapling\n",
    "    [0.4742, 0.4685, 0.4941, 0.4055, 0.4014, 0.5132, 0.4943, 0.5278, 0.5125, 0.5354, 0.5153, 0.4373]   # DetectGPT\n",
    "])\n",
    "\n",
    "def paired_t_test(base, data):\n",
    "    n_detectors = data.shape[0]\n",
    "    results = {}\n",
    "    \n",
    "    for i in range(n_detectors):\n",
    "        detector_results = []\n",
    "        \n",
    "        # Compare each variant against the first variant\n",
    "        t_stat, p_val = ttest_rel(base[i], data[i])\n",
    "        detector_results.append((t_stat, p_val))\n",
    "            \n",
    "        results[f\"{i}\"] = detector_results\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Get t-test results for each metric\n",
    "accuracy_results = paired_t_test(data_accuracy_base, data_accuracy)\n",
    "\n",
    "detector_dict = [\"GLTR\",\"GPT-2 Detector\",\"GPTZero\",\"Sapling\",\"DetectGPT\"]\n",
    "\n",
    "# Print results\n",
    "for detector, res in accuracy_results.items():\n",
    "    print(f\"ACC Results for {detector_dict[int(detector)]}:\")\n",
    "    for idx, (t_stat, p_val) in enumerate(res, 1):\n",
    "        print(f\"Summary: t-stat = {t_stat:.4f}, p-value = {p_val:.4f}\")\n",
    "        if p_val < 0.05:\n",
    "            print(\"SIGNIFICANT\")\n",
    "    print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
